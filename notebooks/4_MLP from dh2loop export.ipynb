{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from dh2loop import mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ranee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ranee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ranee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glove import Glove\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pyproj\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "from keras.models import load_model\n",
    "from scipy import interpolate\n",
    "from itertools import product\n",
    "import gdal\n",
    "import ogr\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of original litho classes: 27\n",
      "number of CET_Litho classes : 21\n",
      "unclassified in CET_Litho: 0\n",
      "number of original comment classes: 27\n",
      "number of CET_Comment classes : 21\n",
      "unclassified in CET_Comment: 0\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "DF = mlp.litho_Dataframe('../data/test3.csv', 'dh2loop_export' )\n",
    "\n",
    "# loading word embeddings model\n",
    "model = mlp.load_geovec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 1s - loss: 2.7354 - accuracy: 0.4782\n",
      "Epoch 2/30\n",
      " - 0s - loss: 1.7531 - accuracy: 0.6222\n",
      "Epoch 3/30\n",
      " - 0s - loss: 1.0095 - accuracy: 0.7173\n",
      "Epoch 4/30\n",
      " - 0s - loss: 0.5749 - accuracy: 0.8785\n",
      "Epoch 5/30\n",
      " - 0s - loss: 0.3598 - accuracy: 0.9155\n",
      "Epoch 6/30\n",
      " - 0s - loss: 0.2441 - accuracy: 0.9472\n",
      "Epoch 7/30\n",
      " - 0s - loss: 0.1788 - accuracy: 0.9604\n",
      "Epoch 8/30\n",
      " - 0s - loss: 0.1367 - accuracy: 0.9657\n",
      "Epoch 9/30\n",
      " - 0s - loss: 0.1021 - accuracy: 0.9828\n",
      "Epoch 10/30\n",
      " - 0s - loss: 0.0807 - accuracy: 0.9841\n",
      "Epoch 11/30\n",
      " - 0s - loss: 0.0610 - accuracy: 0.9894\n",
      "Epoch 12/30\n",
      " - 0s - loss: 0.0446 - accuracy: 0.9987\n",
      "Epoch 13/30\n",
      " - 0s - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      " - 0s - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      " - 0s - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      " - 0s - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      " - 0s - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      " - 0s - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      " - 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      " - 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      " - 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      " - 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      " - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      " - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      " - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      " - 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      " - 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      " - 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      " - 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      " - 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "(85, 300)\n",
      "1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 1 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-df3962127f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# assessment of model performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_assess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# save lithological prediction likelihoods dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dh2loop-0.0.1-py3.6.egg/dh2loop/mlp.py\u001b[0m in \u001b[0;36mclassifier_assess\u001b[0;34m(classifier, x, y)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         -y: numpy array with lithological classes predicted'''\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mY2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     print('f1 score: ', metrics.f1_score(y, Y2, average='macro'),\n\u001b[1;32m    235\u001b[0m           \u001b[0;34m'accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dh2loop-0.0.1-py3.6.egg/dh2loop/mlp.py\u001b[0m in \u001b[0;36mretrieve_predictions\u001b[0;34m(classifier, x)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mnew_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mnew_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0mcodes_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodes_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 20 is out of bounds for axis 1 with size 20"
     ]
    }
   ],
   "source": [
    "# getting the mean embeddings of descriptions\n",
    "DF = mlp.mean_embeddings('dh2loop_export.pkl', DF['Company_Litho'], DF['CET_Litho'], model)\n",
    "\n",
    "# subseting dataset for training classifier\n",
    "X, Y, X_test, Y_test, X_train, Y_train, X_validation, Y_validation = mlp.split_stratified_dataset(DF, 0.1, 0.1)# encoding lithological classes\n",
    "one_enc = OneHotEncoder()\n",
    "encodes = one_enc.fit_transform(Y_train).toarray()\n",
    "\n",
    "# MLP model generation\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=300, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(units=len(DF.code.unique()), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training MLP model\n",
    "model.fit(X_train, encodes, epochs=30, batch_size=100, verbose=2)\n",
    "\n",
    "# saving MLP model\n",
    "model.save('mlp_prob_model.h5')\n",
    "\n",
    "# assessment of model performance\n",
    "mlp.classifier_assess(model, X_validation, Y_validation)\n",
    "\n",
    "# save lithological prediction likelihoods dataframe\n",
    "mlp.save_predictions(DF, model, X, 'YSGBpredictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled = resampling('YSGBpredictions.pkl', 'YSGBpredictions_resampled.pkl')\n",
    "#resampled.to_pickle('surveyed2_emb_depth.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEM and shapefile must be in the same projection that the dataframe (in this\n",
    "# case all were projected using crs = epsg:37255)\n",
    "\n",
    "model = load_model('mlp_prob_model.h5')\n",
    "dataPath = 'surveyed2_emb_depth.pkl'\n",
    "shapefilePath = 'Moree.shp'\n",
    "demPath = 'MoreeDem.tif'\n",
    "#demPath = '/home/ignacio/Documents/chapter2/DEM_NSW.tif'\n",
    "\n",
    "subset_data = get_subset(dataPath, shapefilePath)\n",
    "\n",
    "geo2D_data = get_2D(dataPath, shapefilePath, demPath, 100)\n",
    "np.save('points_Moree_Ln.npy', geo2D_data)\n",
    "\n",
    "recake = get_3D(geo2D_data, subset_data, 100, depthMask=175, xMask=772500, yMask=6740000)\n",
    "np.save('MoreeRecakeLn.npy', recake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo2D_path = 'points_Moree_Ln.npy'\n",
    "geo3D_path = 'MoreeRecakeLn.npy'\n",
    "\n",
    "data1 = np.load(geo2D_path)\n",
    "processed3D = preprocess_3Ddata(geo3D_path)\n",
    "processed2D = preprocess_2Ddata(geo2D_path)\n",
    "patches = [mpatches.Patch(color=litho_colors[n], label=litho_classes[n]) for n in np.unique(processed2D[:, 3])]\n",
    "facecolors = np.array([litho_colors.get(i, -1) for i in range(processed3D.min(), processed3D.max() + 1)])\n",
    "facecolors = facecolors[(processed3D - processed3D.min())]\n",
    "facecolors = explode(facecolors)\n",
    "filled = facecolors[:, :, :, -1] != 0\n",
    "z, y, x = expand_coordinates(np.indices(np.array(filled.shape) + 1))\n",
    "\n",
    "figure = plot3D(x, y, z, data1, processed2D, filled, facecolors, 'Lin')\n",
    "figure.savefig('test.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = 'NSWpredictions.pkl'\n",
    "\n",
    "ents, quants = get_entropies(embeddings_path, model)\n",
    "figure = classification_entropies(ents, quants, cols, patches, classes)\n",
    "\n",
    "Moree = get_subset(dataPath, shapefilePath)\n",
    "uncsss = uncertainties2D(Moree, 10, model, demPath)\n",
    "Confusion2D = CI_points(uncsss, True)\n",
    "Entropy2D = Ent_points(uncsss, True)\n",
    "Ent3D = get_3D(Entropy2D, Moree, 100,\n",
    "               depthMask=175, xMask=772500, yMask=6740000)\n",
    "print(np.nanmax(Ent3D), np.nanmin(Ent3D), np.nanmean(Ent3D))\n",
    "\n",
    "CI3D = get_3D(Confusion2D, Moree, 100,\n",
    "              depthMask=175, xMask=772500, yMask=6740000)\n",
    "print(np.nanmax(CI3D), np.nanmin(CI3D), np.nanmean(CI3D))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
