{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\00103098\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\00103098\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\00103098\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from dh2loop import dh2l_db\n",
    "import datetime\n",
    "#from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default parameters loaded from DH2_LConfig.py:\n",
      "from datetime import datetime\n",
      "#Extents to query \n",
      "#ranee\n",
      "minlong=115.5\n",
      "maxlong=118\n",
      "minlat=-30.5\n",
      "maxlat=-27.5\n",
      "\n",
      "#fabilea\n",
      "#minlong=121.2\n",
      "#maxlong=122.89\n",
      "#minlat=-21.04\n",
      "#maxlat=-21.03\n",
      "\n",
      "\n",
      "#src_pro,Dst_proj\n",
      "src_csr = 4326 \n",
      "dst_csr = 28350\n",
      "\n",
      "\n",
      "#ExportFiles\n",
      "nowtime=datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")   #.isoformat(timespec='minutes')\n",
      "export_path='../data/export_db/'\n",
      "DB_Collar_Rl_Log = export_path + 'DB_Collar_Rl_Log_' + nowtime + '.log'\n",
      "DB_Collar_Maxdepth_Log = export_path + 'DB_Collar_maxdepth_Log_' + nowtime +'.log'\n",
      "DB_Collar_Export=export_path+'DB_Collar_Export_' + nowtime + '.csv'   #.replace(\"-\",\"/\").replace(\"T\",\" At \")\n",
      "DB_Survey_Export=export_path+'DB_Survey_Export_'+ nowtime +'.csv'\n",
      "DB_Survey_Export_Calc=export_path+'DB_Survey_Export_Calc_'+ nowtime +'.csv'\n",
      "CET_Litho=export_path+'CET_Litho_'+ nowtime +'.csv'\n",
      "DB_Lithology_Export=export_path+'DB_Lithology_Export_'+ nowtime +'.csv'\n",
      "DB_Lithology_Export_Backup=export_path+'DB_Lithology_Export_Backup_'+ nowtime +'.csv'\n",
      "DB_Lithology_Upscaled_Export=export_path+'DB_Lithology_Upscaled_Export_'+ nowtime +'.csv'\n",
      "Upscaled_Litho_NoDuplicates_Export = export_path+'Upscaled_Litho_NoDuplicates_Export_'+ nowtime +'.csv'\n",
      "DB_Lithology_Export_Calc=export_path+'DB_Lithology_Export_Calc_'+ nowtime +'.csv'\n",
      "DB_Lithology_Export_VTK=export_path+'DB_Lithology_Export_'+ nowtime +'.vtp'\n",
      "\n",
      "print('Default parameters loaded from DH2_LConfig.py:')\n",
      "with open('../notebooks/DH2_LConfig.py', 'r') as myfile:\n",
      "  data = myfile.read()\n",
      "  print(data)\n",
      "  myfile.close()\n",
      "print('\\nModify these parameters in the cell below')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Modify these parameters in the cell below\n"
     ]
    }
   ],
   "source": [
    "%run -i \"DH2_LConfig.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collar Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in Hour_Min_Sec_MilliSec is: 0:01:18.985951\n"
     ]
    }
   ],
   "source": [
    "Start_Time = datetime.now()\n",
    "dh2l_db.collar_attr_col_dic()\n",
    "dh2l_db.collar_collar_attri_Final(DB_Collar_Export,src_csr,dst_csr,minlong,maxlong,minlat,maxlat)\n",
    "End_Time = datetime.now()\n",
    "print(\"Time taken in Hour_Min_Sec_MilliSec is:\", End_Time-Start_Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3249: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in Hour_Min_Sec_MilliSec is: 0:04:22.161012\n"
     ]
    }
   ],
   "source": [
    "Start_Time = datetime.now()\n",
    "dh2l_db.Attr_col_dic()\n",
    "dh2l_db.Survey_Final(DB_Survey_Export,minlong,maxlong,minlat,maxlat)\n",
    "dh2l_db.convert_survey(DB_Collar_Export,DB_Survey_Export,DB_Survey_Export_Calc)\n",
    "End_Time = datetime.now()\n",
    "print(\"Time taken in Hour_Min_Sec_MilliSec is:\", End_Time-Start_Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lithology Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in Hour_Min_Sec_MilliSec is: 0:20:50.192829\n"
     ]
    }
   ],
   "source": [
    "Start_Time = datetime.now()\n",
    "dh2l_db.Attr_Val_Dic()\n",
    "dh2l_db.Litho_Dico()\n",
    "dh2l_db.Clean_Up()\n",
    "dh2l_db.Attr_val_With_fuzzy()\n",
    "dh2l_db.Final_Lithology(DB_Lithology_Export,minlong,maxlong,minlat,maxlat)\n",
    "#dh2l_db.Upscale_lithology(DB_Lithology_Export,DB_Lithology_Upscaled_Export)\n",
    "#dh2l_db.Remove_duplicates_Litho(DB_Lithology_Upscaled_Export,Upscaled_Litho_NoDuplicates_Export)\n",
    "End_Time = datetime.now()\n",
    "print(\"Time taken in Hour_Min_Sec_MilliSec is:\", End_Time-Start_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in Hour_Min_Sec_MilliSec is: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "Start_Time = datetime.now()\n",
    "#dh2l_db.convert_lithology()\n",
    "#dh2l_db.Diff_XYZ()\n",
    "End_Time = datetime.now()\n",
    "print(\"Time taken in Hour_Min_Sec_MilliSec is:\", End_Time-Start_Time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------start First_Filter------------\n",
      "--------start of Final -----------\n",
      "Time taken in Hour_Min_Sec_MilliSec is: 3:01:38.446804\n"
     ]
    }
   ],
   "source": [
    "Start_Time = datetime.now()   # for logging \n",
    "dh2l_db.Attr_COl()\n",
    "dh2l_db.Attr_Val_Dic()\n",
    "dh2l_db.Litho_Dico()\n",
    "dh2l_db.Clean_Up()\n",
    "dh2l_db.First_Filter()\n",
    "dh2l_db.Final_Lithology_old()\n",
    "End_Time = datetime.now()\n",
    "print(\"Time taken in Hour_Min_Sec_MilliSec is:\", End_Time-Start_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "Attr_col_collar_dic_list =[]\n",
    "\n",
    "query =\"\"\" SELECT  thesaurus_collar_elevation.attributecolumn,thesaurus_collar_elevation.cet_attributecolumn  FROM thesaurus_collar_elevation\n",
    "           union all \n",
    "           SELECT  thesaurus_collar_maxdepth.attributecolumn,thesaurus_collar_maxdepth.cet_attributecolumn  FROM thesaurus_collar_maxdepth         \"\"\"\n",
    "#query = \"\"\" select * from thesaurus_collar_elevation \"\"\"\n",
    "conn = None\n",
    "   \n",
    "try:\n",
    "    conn = psycopg2.connect(host=\"130.95.198.59\", port = 5432, database=\"gswa_dh\", user=\"postgres\", password=\"loopie123pgpw\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "\n",
    "    for rec in cur:\n",
    "        Attr_col_collar_dic_list.append(rec)\n",
    "    outputquery = \"COPY ({0}) TO STDOUT WITH CSV HEADER\".format(query)\n",
    "   \n",
    "    with open('Dic_attr_col_collar.csv', 'w',encoding=\"utf-8\") as f:\n",
    "        cur.copy_expert(outputquery, f)\n",
    "        #print(Attr_col_collar_dic_list)    \n",
    "    cur.close()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(error)\n",
    "finally:\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
